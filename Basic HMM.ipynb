{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Components of a Hidden Markov Model:\n",
    "    1. States - POS\n",
    "    2. Observations - headlines\n",
    "    \n",
    "    Probablities required that relate the above two components:\n",
    "    1. Initial Probability: An initial probability distribution over states\n",
    "    2. Final Probability: A final probability distribution over states\n",
    "    3. Transition Probability: a matrix A with the probabilities from going from one state to another\n",
    "    4. Emission probability: a matrix B with the probabilities of an observation being generated from a state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Importing Libraries --\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pprint\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import string\n",
    "import pprint\n",
    "import numpy as np\n",
    "\n",
    "# --Reading the dataset in --\n",
    "ds = pd.read_csv('india-news-headlines.csv') \n",
    "ds = ds.drop(columns=['publish_date', 'headline_category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.head(1000)\n",
    "\n",
    "# -- Text Processing --\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "ds[\"headline_text\"] = ds[\"headline_text\"].apply(lambda x: tknzr.tokenize(x))\n",
    "ds[\"headline_text\"] = ds[\"headline_text\"].apply(lambda word: [word for word in word if word.isalpha()])\n",
    "\n",
    "\n",
    "#Dropping rows that contain empty list\n",
    "drop_list = []\n",
    "for idx in range(0, len(ds)):\n",
    "    if(ds['headline_text'].loc[idx] == []):\n",
    "        drop_list.append(idx)\n",
    "\n",
    "ds = ds.drop(drop_list)\n",
    "ds = ds.reset_index(drop=True)\n",
    "\n",
    "ds['headline_tags'] = ds['headline_text'].apply(nltk.pos_tag)\n",
    "ds['headline_tags'] = ds['headline_tags'].apply(lambda x: [x[1] for x in x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Building Text and Tags Dictionaries --\n",
    "tag_freq = defaultdict(int)\n",
    "words_by_tag = defaultdict(list)\n",
    "emi_freq = defaultdict(list)\n",
    "\n",
    "\n",
    "for idx in range(0, len(ds)):\n",
    "    text = ds.iloc[idx]['headline_text']\n",
    "    tags = ds.iloc[idx]['headline_tags']\n",
    "\n",
    "    for index, tag in enumerate(tags):\n",
    "        tag_freq[tag] += 1\n",
    "        words_by_tag[tag].append(text[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- All headline text (observations) in a list --\n",
    "l = ds['headline_text'].tolist()\n",
    "headline_text_list = []\n",
    "for sublist in l:\n",
    "    for item in sublist:\n",
    "        headline_text_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Building Probability Matrices --\n",
    "tags_list = sorted(tag_freq.keys())\n",
    "tags_tuple = tuple(tags_list)\n",
    "\n",
    "trans_prob_matrix = (pd.DataFrame(columns=tags_list, index=tags_list)).fillna(0)\n",
    "initial_prob_matrix = pd.DataFrame(columns=['Count'], index=tags_list).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Building Initial Probability Matrix -- \n",
    "\n",
    "for idx in ds['headline_tags']:\n",
    "    initial_prob_matrix.loc[idx[0]] =  initial_prob_matrix.loc[idx[0]]+1\n",
    "initial_prob_matrix = initial_prob_matrix['Count'].divide(len(ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Building Transition Probability Matrix -- \n",
    "import operator\n",
    "\n",
    "\n",
    "for tags in ds['headline_tags']: \n",
    "    for tag_idx in range(0, len(tags)-1):\n",
    "        trans_prob_matrix[tags[tag_idx+1]][tags[tag_idx]] = trans_prob_matrix[tags[tag_idx+1]][tags[tag_idx]]+1\n",
    "for index, row in trans_prob_matrix.iterrows():\n",
    "    trans_prob_matrix.loc[index] /= trans_prob_matrix.loc[index].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Supporting Data Structures --\n",
    "# -- word_freq = {'tag' : ['word1', 'word2'...]}\n",
    "# -- \n",
    "\n",
    "all_words_l = []\n",
    "\n",
    "# Getting a list of all unique words in the headlines. This list will be used to get columns for the emission probability matrix\n",
    "for key in words_by_tag: #Get the list of words for each tag\n",
    "    l = words_by_tag[key]\n",
    "    u_e = sorted(set(l)) #Get unique words from that list\n",
    "    all_words_l.append(u_e)\n",
    "    words_by_tag[key] = u_e\n",
    "all_words_l = [item for sublist in all_words_l for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Building Transition Probability Matrix -- \n",
    "\n",
    "emission_prob_matrix = pd.DataFrame(columns=all_words_l, index=tags_list).fillna(0)\n",
    "\n",
    "for key in words_by_tag: #Get the list of words for each tag\n",
    "    l_words = words_by_tag[key]\n",
    "    for idx in range(0, len(l_words)):\n",
    "        word = l_words[idx]\n",
    "        emission_prob_matrix.loc[key][word] = emission_prob_matrix.loc[key][word]+1\n",
    "for index, row in emission_prob_matrix.iterrows():\n",
    "    emission_prob_matrix.loc[index] /= emission_prob_matrix.loc[index].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = tags_list\n",
    "M = ds[\"headline_text\"]\n",
    "pi = initial_prob_matrix\n",
    "A = trans_prob_matrix\n",
    "B = emission_prob_matrix\n",
    "O = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DT']\n",
      "DT\n",
      "NNP\n",
      "NNP\n",
      "NNP\n",
      "TO\n",
      "VB\n",
      "IN\n",
      "NNP\n",
      "['this D CTBT Gaya To put if Drumming Angolan ']\n"
     ]
    }
   ],
   "source": [
    "# -- T : number of observations in the sequence --\n",
    "T = 10\n",
    "\n",
    "# -- STEP 1: Choosing an initial state according to the initial state distribution - pi --\n",
    "q1 = np.random.choice(N, 1, p=pi)\n",
    "# -- STEP 2: set t=1\n",
    "t = 1\n",
    "\n",
    "# -- STEP 3: Choose observation according to the emission probability\n",
    "p = np.array(list(B.loc[q1[0]]))\n",
    "p /=  p.sum()\n",
    "O_t = np.random.choice(B.columns.values, 1, p=p)\n",
    "O = O_t[0]+' '\n",
    "\n",
    "# -- STEP 4: Transit to new state according to the state transition probability\n",
    "\n",
    "t=t+1\n",
    "qt = q1\n",
    "print(qt)\n",
    "while t < T:\n",
    "    print(qt[0])\n",
    "    qt = np.random.choice(N, 1, p=A.loc[qt[0]])\n",
    "    p = np.array(list(B.loc[qt[0]]))\n",
    "    p /=  p.sum()\n",
    "    O_t = np.random.choice(B.columns.values, 1, p=p)\n",
    "    O = O + O_t + ' '\n",
    "    t+=1\n",
    "print(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
